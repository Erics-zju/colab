{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9a0a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 14:43:42.197805: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753253022.211983 1657444 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753253022.216230 1657444 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753253022.228332 1657444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753253022.228344 1657444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753253022.228346 1657444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753253022.228347 1657444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-23 14:43:42.232815: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/xthu/miniforge3/envs/OXEdatasets/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from matplotlib import font_manager as fm\n",
    "\n",
    "font_path = \"/home2/qrchen/GillSans.ttc\"\n",
    "font_prop = fm.FontProperties(fname=font_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830685b",
   "metadata": {},
   "source": [
    "## 倒入pakage 并且define 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b4842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home2/qrchen/embodied-datasets/metadata.csv')\n",
    "\n",
    "TRAIN_SPLIT = 'train[:10]'  \n",
    "FRAME_SKIP_DEFAULT = 5\n",
    "FRAME_SKIP_LARGE = 10  # 当帧数>100时使用\n",
    "LARGE_FRAME_THRESHOLD = 100\n",
    "THIRD_PERSON_FRAME_THRESHOLD = 1000\n",
    "RESIZE_FACTOR = 1\n",
    "MAX_EPISODES = 10\n",
    "\n",
    "DATASET_CONFIG = {\n",
    "    \"dataset_name_in_csv\": \"RoboSet\",\n",
    "    \"language_field\": \"language_instruction\",\n",
    "    \"observation_field\": \"observation\",\n",
    "    \"image_fields\": [\"image_left\",\"image_right\",\"image_top\",\"image_wrist\"],\n",
    "    \"depth_fields\": []\n",
    "}\n",
    "\n",
    "# 从df 中找到 DATASET_CONFIG 中 dataset_name_in_csv 对应的 行，得到其中 nickname 的值\n",
    "dataset_name_in_csv = DATASET_CONFIG[\"dataset_name_in_csv\"]\n",
    "dataset = df[df['Datasets'] == dataset_name_in_csv]\n",
    "dataset = dataset['NickName'].item()\n",
    "OUTPUT_DIR = f\"{dataset}/sample\"\n",
    "\n",
    "\n",
    "def dataset2path(dataset_name):\n",
    "  if dataset_name == 'robo_net':\n",
    "    version = '1.0.0'\n",
    "  elif dataset_name == 'language_table' or dataset_name == 'robo_set':\n",
    "    version = '0.0.1'\n",
    "  else:\n",
    "    version = '0.1.0'\n",
    "  return f'gs://gresearch/robotics/{dataset_name}/{version}'\n",
    "\n",
    "# ============ 工具函数 ============\n",
    "def depth_to_color_img(depth):\n",
    "    \"\"\"将depth转为彩色图像\"\"\"\n",
    "    d = depth.copy()\n",
    "    d = (d - np.nanmin(d)) / (np.nanmax(d) - np.nanmin(d) + 1e-8)\n",
    "    cm = plt.get_cmap('jet')\n",
    "    colored = cm(d)[:, :, :3]  # 只要RGB，不要alpha\n",
    "    colored = (colored * 255).astype(np.uint8)\n",
    "    return colored\n",
    "\n",
    "def as_gif(images, path=\"temp.gif\", resize_factor=0.5):\n",
    "    \"\"\"生成GIF文件\"\"\"\n",
    "    if resize_factor != 1.0:\n",
    "        resized_images = []\n",
    "        for img in images:\n",
    "            width, height = img.size\n",
    "            new_size = (int(width * resize_factor), int(height * resize_factor))\n",
    "            resized_images.append(img.resize(new_size, Image.Resampling.LANCZOS))\n",
    "        images = resized_images\n",
    "    \n",
    "    images[0].save(path, save_all=True, append_images=images[1:], duration=int(1000/15), loop=0)\n",
    "    gif_bytes = open(path,\"rb\").read()\n",
    "    return gif_bytes\n",
    "\n",
    "def get_language_instruction(episode, config):\n",
    "    \"\"\"提取语言指令\"\"\"\n",
    "    for step in episode[\"steps\"]:\n",
    "        lang_inst = step[config[\"language_field\"]].numpy()\n",
    "        if isinstance(lang_inst, bytes):\n",
    "            lang_inst = lang_inst.decode('utf-8')\n",
    "        return lang_inst\n",
    "    return \"\"\n",
    "\n",
    "def process_single_step(obs, config):\n",
    "    \"\"\"处理单帧数据，返回拼接的图像和深度图像\"\"\"\n",
    "    # 提取RGB图像\n",
    "    rgb_images = []\n",
    "    for field in config[\"image_fields\"]:\n",
    "        # 处理嵌套图像路径\n",
    "        if isinstance(field, tuple):\n",
    "            field_name, sub_field_name = field\n",
    "            rgb_images.append(obs[field_name][sub_field_name].numpy())\n",
    "        else:\n",
    "            rgb_images.append(obs[field].numpy())\n",
    "    concat_rgb = np.concatenate(rgb_images, axis=1)\n",
    "    \n",
    "    # 提取并处理深度图像\n",
    "    depth_images = []\n",
    "    if len(config[\"depth_fields\"]) > 0:\n",
    "      for field in config[\"depth_fields\"]:\n",
    "        depth_img = obs[field].numpy()\n",
    "        color_depth = depth_to_color_img(depth_img)\n",
    "        depth_images.append(color_depth)\n",
    "    else:\n",
    "      depth_images.append(np.zeros_like(concat_rgb))\n",
    "    concat_depth = np.concatenate(depth_images, axis=1) \n",
    "    \n",
    "    return Image.fromarray(concat_rgb), Image.fromarray(concat_depth)\n",
    "\n",
    "def process_episode(episode, episode_idx, config):\n",
    "    \"\"\"处理单个episode\"\"\"\n",
    "    # 获取语言指令\n",
    "    lang_inst = get_language_instruction(episode, config)\n",
    "    if lang_inst == \"\":\n",
    "        return None\n",
    "    \n",
    "    print(f\"Language Instruction: {lang_inst}\")\n",
    "    \n",
    "    # 动态调整帧抽取\n",
    "    total_frames = len(list(episode['steps']))\n",
    "    frame_skip = FRAME_SKIP_LARGE if total_frames > LARGE_FRAME_THRESHOLD else FRAME_SKIP_DEFAULT\n",
    "    print(f\"当前episode总帧数: {total_frames}, 抽取帧数: {frame_skip}\")\n",
    "    \n",
    "    # 收集图像\n",
    "    rgb_images = []\n",
    "    depth_images = []\n",
    "    \n",
    "    for step_idx, step in enumerate(episode[\"steps\"]):\n",
    "        if step_idx % frame_skip == 0:\n",
    "            obs = step[config[\"observation_field\"]]\n",
    "            rgb_img, depth_img = process_single_step(obs, config)\n",
    "            rgb_images.append(rgb_img)\n",
    "            # depth_images.append(depth_img)\n",
    "    \n",
    "    # 生成文件名\n",
    "    safe_filename = lang_inst.replace(\" \", \"_\").replace(\".\", \"\")\n",
    "    rgb_path = f\"{OUTPUT_DIR}/{safe_filename}_{episode_idx}_image.gif\"\n",
    "    depth_path = f\"{OUTPUT_DIR}/{safe_filename}_{episode_idx}_depth.gif\"\n",
    "    \n",
    "    # 保存GIF\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    display.Image(as_gif(rgb_images, rgb_path, RESIZE_FACTOR))\n",
    "    # display.Image(as_gif(depth_images, depth_path, RESIZE_FACTOR))\n",
    "    print(f\"已生成GIF文件: {rgb_path}, {depth_path}\")\n",
    "    \n",
    "    return {\n",
    "        \"total_frames\": total_frames,\n",
    "        \"processed_frames\": len(rgb_images),\n",
    "        \"rgb_path\": rgb_path,\n",
    "        \"depth_path\": depth_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7793ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict, Counter\n",
    "import pprint\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fef73",
   "metadata": {},
   "source": [
    "## Read and build data from dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565e9379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 14:53:07.552253: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753253587.562552 1664277 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753253587.566926 1664277 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753253587.579807 1664277 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753253587.579820 1664277 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753253587.579822 1664277 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753253587.579823 1664277 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-23 14:53:07.584456: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-23 14:53:08.850617: W external/local_xla/xla/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Could not resolve hostname', error details: Could not resolve host: metadata.google.internal\".\n",
      "W0000 00:00:1753253592.610620 1664277 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "b = tfds.builder_from_directory(builder_dir=dataset2path(dataset))\n",
    "ds = b.as_dataset(split=TRAIN_SPLIT)  # 用100的缓冲区用于打乱，取其中的10条"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2a51d",
   "metadata": {},
   "source": [
    "## 生产GIF 图片，旧版本，先不要使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713b67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# print(\"开始读取数据...\")\n",
    "# for episode_idx, episode in enumerate(ds):  # type: ignore\n",
    "#     print(f\"\\n=== Episode {episode_idx + 1} ===\")\n",
    "    \n",
    "#     result = process_episode(episode, episode_idx, DATASET_CONFIG)\n",
    "#     if result is None:\n",
    "#         continue \n",
    "#     count += 1\n",
    "#     if count >= 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad852330",
   "metadata": {},
   "source": [
    "## 统计数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e38f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2025-07-23 14:53:16.587894: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-07-23 14:53:25.717272: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-07-23 14:53:25.764380: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "1it [00:09,  9.19s/it]2025-07-23 14:53:25.834676: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "3it [00:09,  2.44s/it]2025-07-23 14:53:25.979203: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "6it [00:13,  2.01s/it]2025-07-23 14:53:30.402633: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "10it [00:13,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Mean frames per episode: 94.00\n",
      "Standard deviation of frames: 18.00\n",
      "总episode数: 10，总instruction数: 10，去重后instruction数: 7\n",
      "--------------------------------\n",
      "所有instruction的数量:10\n",
      "所有的instruction: ['Drag mug right to left.', 'Pick up the butter.', 'Drag mug backwards.', 'Drag mug forwards.', 'Flap open oven.', 'Drag strainer right to left.', 'Drag strainer forwards.', 'Drag mug backwards.', 'Drag mug backwards.', 'Drag strainer forwards.']\n",
      "所有的instruction去重后数: 7\n",
      "所有的instruction去重后:\n",
      "Drag strainer forwards.\n",
      "Drag mug forwards.\n",
      "Flap open oven.\n",
      "Drag strainer right to left.\n",
      "Pick up the butter.\n",
      "Drag mug backwards.\n",
      "Drag mug right to left.\n",
      "Counter({'Drag mug backwards.': 3, 'Drag strainer forwards.': 2, 'Drag mug right to left.': 1, 'Pick up the butter.': 1, 'Drag mug forwards.': 1, 'Flap open oven.': 1, 'Drag strainer right to left.': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 1. 统计动词和动词短语\n",
    "frame_num = []\n",
    "task_list = []\n",
    "def extract_verbs_and_phrases_from_tasks(task_list):\n",
    "    \"\"\"\n",
    "    从英语任务列表中提取动词和动词短语，并统计它们的出现次数。\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    verbs_and_phrases = []\n",
    "    for task in task_list:\n",
    "        doc = nlp(task)\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"VERB\":\n",
    "                verbs_and_phrases.append(token.text.lower())\n",
    "                phrase = [token.text.lower()]\n",
    "                for child in token.children:\n",
    "                    if child.pos_ in [\"PART\", \"ADV\"]:\n",
    "                        phrase.append(child.text.lower())\n",
    "                if len(phrase) > 1:\n",
    "                    verbs_and_phrases.append(\" \".join(phrase))\n",
    "    counts = Counter(verbs_and_phrases)\n",
    "    return dict(counts)\n",
    "\n",
    "# 2. 统计帧数和收集instruction\n",
    "\n",
    "def get_instructions_and_frame_stats(ds):\n",
    "    task_list = []\n",
    "    frame_num = []\n",
    "    for episode_idx, episode in tqdm(enumerate(ds)):\n",
    "        step_0 = list(episode['steps'])[0]\n",
    "        if 'natural_language_instruction' in step_0['observation']:\n",
    "            task = step_0['observation']['natural_language_instruction'].numpy().decode('utf-8')\n",
    "        elif 'language_instruction' in step_0:\n",
    "            task = step_0['language_instruction'].numpy().decode('utf-8')\n",
    "        else:\n",
    "            instruction_bytes = step_0[\"observation\"][\"instruction\"]\n",
    "            instruction_encoded = tf.strings.unicode_encode(instruction_bytes, output_encoding=\"UTF-8\")\n",
    "            task = tf.strings.split(instruction_encoded, \"\\x00\")[0].numpy().decode('utf-8')\n",
    "        task_list.append(task)\n",
    "        frame_num.append(len(list(episode['steps'])))\n",
    "    return task_list, frame_num\n",
    "\n",
    "task_list, frame_num = get_instructions_and_frame_stats(ds)\n",
    "\n",
    "# 3. 统计帧数均值和标准差\n",
    "# 每一个episode统计帧数均值和标准差\n",
    "mean_frames = np.mean(frame_num) if frame_num else 0\n",
    "std_frames = np.std(frame_num) if frame_num else 0\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Mean frames per episode: {mean_frames:.2f}\")\n",
    "print(f\"Standard deviation of frames: {std_frames:.2f}\")\n",
    "print(f\"总episode数: {len(frame_num)}，总instruction数: {len(task_list)}，去重后instruction数: {len(set(task_list))}\")\n",
    "# 统计动词和动词短语\n",
    "# verb_stats = extract_verbs_and_phrases_from_tasks(task_list)\n",
    "# print(\"动词和动词短语统计:\")\n",
    "# for k, v in sorted(verb_stats.items(), key=lambda x: -x[1]):\n",
    "#     print(f\"{k}: {v}\")\n",
    "# print(f\"总动词和动词短语数: {len(verb_stats)}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"所有instruction的数量:{len(task_list)}\")\n",
    "print(f\"所有的instruction: {task_list}\")\n",
    "print(f\"所有的instruction去重后数: {len(set(task_list))}\")\n",
    "print(f\"所有的instruction去重后:\")\n",
    "for i in set(task_list):\n",
    "    print(i)\n",
    "print(Counter(task_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457aa8f",
   "metadata": {},
   "source": [
    "## 按照MAX_TASKS 个task 生成 gif 图片，并且保存在对应的samples/路径下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d0113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  1.72s/it]2025-07-23 14:37:49.658274: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "8it [00:16,  2.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Drag strainer forwards.': ['0.gif', '1.gif'],\n",
       "             'Drag strainer right to left.': ['0.gif'],\n",
       "             'Drag mug forwards.': ['0.gif'],\n",
       "             'Flap open oven.': ['0.gif'],\n",
       "             'Drag mug backwards.': ['0.gif', '1.gif'],\n",
       "             'Drag mug right to left.': ['0.gif']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from PIL.ImageQt import rgb \n",
    "save_root = f\"/home2/qrchen/embodied-datasets/Trajectories/{dataset}\"\n",
    "os.makedirs(os.path.join(save_root, \"samples\"), exist_ok=True)\n",
    "\n",
    "\n",
    "target_fps = 1\n",
    "fps=10\n",
    "frame_skip = 10\n",
    "\n",
    "# 每个task 最多的 trajectory 数\n",
    "MAX_TRAJECTORIES_PER_TASK = 2\n",
    "# 最多生成多少个task，如果一共有100 个task，那么我们只会输出 MAX_TASKS 个task\n",
    "MAX_TASKS = 5\n",
    "\n",
    "\n",
    "# 1. 统计每个任务的轨迹数\n",
    "file_name_list = [] # 每个task 的 trajectory 数\n",
    "task_counters = defaultdict(list) # 每个task 的 trajectory 数\n",
    "\n",
    "# 2. 遍历每个轨迹，统计每个任务的轨迹数\n",
    "for episode_idx, episode in tqdm(enumerate(ds)):\n",
    "\n",
    "    # 2.1 如果任务数超过最大任务数，则跳过\n",
    "    if len(task_counters.keys()) > MAX_TASKS:\n",
    "        break\n",
    "\n",
    "    task = ''\n",
    "    step_0 = list(episode['steps'])[0]# 获取轨迹的第一个step\n",
    "    # 2.2 获取任务 遍历 嵌套字典\n",
    "    if 'natural_language_instruction' in step_0['observation']: \n",
    "        task = step_0['observation']['natural_language_instruction'].numpy().decode('utf-8')\n",
    "    elif 'language_instruction' in step_0:\n",
    "        task = step_0['language_instruction'].numpy().decode('utf-8')\n",
    "    else:\n",
    "        instruction_bytes = step_0[\"observation\"][\"instruction\"]\n",
    "        instruction_encoded = tf.strings.unicode_encode(instruction_bytes, output_encoding=\"UTF-8\")\n",
    "        task = tf.strings.split(instruction_encoded, \"\\x00\")[0].numpy().decode('utf-8')\n",
    "\n",
    "    # 2.3 如果任务为空，则跳过  \n",
    "    if not len(task):\n",
    "        continue\n",
    "\n",
    "\n",
    "    # 2.4 如果任务数超过最大任务数，则跳过\n",
    "    if task in task_counters and len(task_counters[task]) >= MAX_TRAJECTORIES_PER_TASK:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    rgb_images = []\n",
    "    for step_index ,step in enumerate(episode['steps']):\n",
    "        if step_index % frame_skip == 0:\n",
    "            obs = step[DATASET_CONFIG[\"observation_field\"]]\n",
    "            rgb_img, depth_img = process_single_step(obs, DATASET_CONFIG) #这里掉用了 process_single_step 函数，这个函数在 debug-xintong.ipynb 中\n",
    "            rgb_images.append(rgb_img)\n",
    "\n",
    "    \n",
    "    if task not in task_counters or len(task_counters[task]) < MAX_TRAJECTORIES_PER_TASK:\n",
    "        if rgb_images:\n",
    "            task_filename = task.replace(\" \", \"_\").replace(\".\", \"\")\n",
    "            \n",
    "            current_count = len(task_counters[task])\n",
    "            gif_path= os.path.join(save_root, \"samples\", task_filename, f\"{current_count}.gif\")\n",
    "            os.makedirs(os.path.dirname(gif_path), exist_ok=True)\n",
    "            task_counters[task].append(f\"{current_count}.gif\")\n",
    "            display.Image(as_gif(rgb_images, gif_path, RESIZE_FACTOR))\n",
    "\n",
    "\n",
    "task_counters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4819f3",
   "metadata": {},
   "source": [
    "## Modify javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "\n",
    "with open('/home2/qrchen/embodied-datasets/Templates/script.js', 'r', encoding='utf-8') as f:\n",
    "    js_template = Template(f.read())\n",
    "\n",
    "filled_js = js_template.render(\n",
    "    gif_paths=pprint.pformat(dict(task_counters))\n",
    ")\n",
    "\n",
    "with open(os.path.join(save_root, 'script.js'), 'w', encoding='utf-8') as f:\n",
    "    f.write(filled_js)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f631cd",
   "metadata": {},
   "source": [
    "## Modify html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home2/qrchen/embodied-datasets/metadata.csv')\n",
    "\n",
    "with open(\"/home2/qrchen/embodied-datasets/Templates/index.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "dataset_name_in_csv = DATASET_CONFIG[\"dataset_name_in_csv\"]\n",
    "metadata = df[df['Datasets'] == dataset_name_in_csv] #得到这一行的数据\n",
    "\n",
    "\n",
    "\n",
    "episodes = metadata['#Trajectories'].item().replace('\\n', '<br>')\n",
    "contents = f\"\"\"\n",
    "<h3>\n",
    "Basic Information\n",
    "</h3>\n",
    "<p>\n",
    "    <span class=\"highlight-label\">#Tasks:</span> {metadata['#Tasks'].item()}\n",
    "    <br>\n",
    "    <span class=\"highlight-label\">#Scenes:</span> {metadata['#Scenes'].item()}\n",
    "    <br>\n",
    "    <span class=\"highlight-label\">#Episodes:</span> {episodes}\n",
    "    <br>\n",
    "    <span class=\"highlight-label\">Avg Frames per episode:</span> {metadata['Avg. frames/ trajectory'].item()}\n",
    "    <br>\n",
    "    <span class=\"highlight-label\">Instruction:</span> {metadata['Language instructions'].item()}\n",
    "</p>\n",
    "<br>\n",
    "<br>\n",
    "<h3>\n",
    "How to modify?\n",
    "</h3>\n",
    "<p>\n",
    "{metadata['How to modify it to align with our overall objectives?'].item()}\n",
    "</p>\n",
    "\"\"\"\n",
    "\n",
    "html_content = html_content.replace(\"==TITLE==\", metadata[\"Datasets\"].item())\n",
    "html_content = html_content.replace(\"==Contents==\", contents)\n",
    "\n",
    "# 保存到新路径\n",
    "with open(os.path.join(save_root, 'index.html'), 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bee7ec",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OXEdatasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
